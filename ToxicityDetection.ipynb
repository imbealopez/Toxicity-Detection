{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicityDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbealopez/Toxicity-Detection/blob/master/ToxicityDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2DgZ9z-3RCSC",
        "colab": {}
      },
      "source": [
        "# essential imports\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import warnings  # Ignore warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re  # regular expressions\n",
        "import math  # math functions\n",
        "import scipy.stats as stats\n",
        "import random  # random numbers and generator\n",
        "import copy  # copy objects\n",
        "import pickle  # copy objects into binary files\n",
        "import timeit  # timer\n",
        "import os  # system functions\n",
        "import sys\n",
        "import datetime\n",
        "import pkg_resources\n",
        "\n",
        "# import seaborn as sns\n",
        "import matplotlib.pyplot as plt  # plotting tool\n",
        "\n",
        "# scikit-learn\n",
        "# evaluation metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# preprocess text\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from preprocess import cleanUp\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "\n",
        "# tensorflow\n",
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "\n",
        "# evaluation metrics\n",
        "import metricsbias  # bias metrics\n",
        "from metricsoverall import JigsawEvaluator  # overall metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrMCmVW-XQDp",
        "colab_type": "text"
      },
      "source": [
        "# Load data and set defaults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzs_gPkvRi-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page. \n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "%cd /content/\n",
        "\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# List available datasets.\n",
        "#!kaggle datasets list\n",
        "# download dataset from api\n",
        "!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification\n",
        "\n",
        "#unzip train and test sets into data directory\n",
        "!unzip train.csv.zip -d ./data\n",
        "!unzip test_private_expanded.csv.zip -d ./data\n",
        "!unzip test_public_expanded.csv.zip -d ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x0w3GppRUOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set defaults\n",
        "#%matplotlib inline\n",
        "plt.ion()\n",
        "# pd options\n",
        "# pd.set_option(\"display.max_columns\", 500)\n",
        "# pd.set_option(\"display.max_rows\", 500)\n",
        "# pd.set_option(\"display.width\", 1000)\n",
        "\n",
        "\n",
        "# default seeding for reproducability\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "# toxicity score column\n",
        "TOXICITY_COLUMN = \"target\"\n",
        "# text comment column\n",
        "TEXT_COLUMN = \"comment_text\"\n",
        "# List all identities\n",
        "# target and subgroup columns\n",
        "\n",
        "identity_columns = [\n",
        "    \"male\",\n",
        "    \"female\",\n",
        "    \"homosexual_gay_or_lesbian\",\n",
        "    \"christian\",\n",
        "    \"jewish\",\n",
        "    \"muslim\",\n",
        "    \"black\",\n",
        "    \"white\",\n",
        "    \"psychiatric_or_mental_illness\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhK4D6gQVWuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Load train and test comments\n",
        "train_comments = pd.read_csv('/content/data/train.csv')\n",
        "test_private_comments = pd.read_csv('/content/data/test_private_expanded.csv')\n",
        "test_public_comments = pd.read_csv('/content/data/test_public_expanded.csv')\n",
        "\n",
        "\n",
        "print(\"loaded %d records\" % len(train_comments))\n",
        "#%%\n",
        "# display head\n",
        "train_comments.head()\n",
        "# display first comment\n",
        "train_comments.iloc[0][\"comment_text\"]\n",
        "# display toxic comments above target 0.5\n",
        "train_comments[train_comments[\"target\"] >= 0.5].head()\n",
        "# shuffle\n",
        "# train_comments = train_comments.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2-5MW6pXF94",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-nxOdJzWZDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %%\n",
        "# TODO test preprocessing\n",
        "\n",
        "# Make sure all comment_text values are strings\n",
        "train_comments[\"comment_text\"] = train_comments[\"comment_text\"].astype(str)\n",
        "\n",
        "\n",
        "\n",
        "# Convert taget and identity columns to booleans\n",
        "def convert_to_bool(df, col_name):\n",
        "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
        "    # df.loc[df.col_name >= 0.5, col_name] = True\n",
        "    # df.loc[df.col_name < 0.5, col_name] = False\n",
        "\n",
        "\n",
        "def convert_dataframe_to_bool(df):\n",
        "    bool_df = df.copy()\n",
        "    for col in [\"target\"] + identity_columns:\n",
        "        convert_to_bool(bool_df, col)\n",
        "    return bool_df\n",
        "\n",
        "#%%\n",
        "train_comments = convert_dataframe_to_bool(train_comments)\n",
        "\n",
        "# train_comments.loc[:, \"comment_text\"] = train_comments.comment_text.apply(cleanUp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h1NawP_Wp0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %%\n",
        "# comment-target split\n",
        "full_labels = train_comments.iloc[:][\"target\"].copy()\n",
        "full_comments = train_comments[[\"comment_text\"]].copy()\n",
        "print(full_labels.head())\n",
        "print(full_comments.head())\n",
        "\n",
        "# split train into training-evaluation set 80%-20%\n",
        "# x_train, x_eval, y_train, y_eval = train_test_split(\n",
        "#     full_comments, full_labels, test_size=0.2, random_state=42, shuffle=False\n",
        "# )\n",
        "# array form\n",
        "# x_train.values\n",
        "\n",
        "train_df, validate_df = train_test_split(\n",
        "    train_comments, test_size=0.2, random_state=42, shuffle=False\n",
        ")\n",
        "\n",
        "print(\"%d train comments, %d validate comments\" % (len(train_df), len(validate_df)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxN98jVWqN7",
        "colab_type": "text"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOj4ugyeWmUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# TODO setup and run model\n",
        "MODEL_NAME = \"my_model\"\n",
        "# validate_df[MODEL_NAME] = model.predict(pad_text(validate_df[TEXT_COLUMN], tokenizer))[:, 1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr0sRf-jWvtK",
        "colab_type": "text"
      },
      "source": [
        "# Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaSHJttkWl7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%\n",
        "\n",
        "y_true = validate_df[\"target\"].values\n",
        "y_identity = validate_df[identity_columns].values\n",
        "\n",
        "# predict\n",
        "# TODO add model\n",
        "# y_pred = model.predict_proba(train_df)\n",
        "\n",
        "# evaluate\n",
        "# evaluator = JigsawEvaluator(y_true, y_identity)\n",
        "# auc_score = evaluator.get_final_metric(y_pred)\n",
        "\n",
        "# uncomment to show only bias metric\n",
        "# bias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
        "# bias_metrics_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}